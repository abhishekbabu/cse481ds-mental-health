plot(dat_1$x1,dat_1$y)
cor(dat_2)
lm.second <- lm(y ~ x2 + x1*x2, data = dat_2)
summary(lm.second)
lm.second <- lm(y ~ x1*x2, data = dat_2)
summary(lm.second)
cor(dat_2)
lm.second <- lm(y ~ x2, data = dat_2)
summary(lm.second)
plot(dat_1$x1*dat_1$x2,dat_1$y)
cor(dat_1$x1*dat_1$x2,dat_1$y)
cor(dat_1)
summary(lm(y ~ x1 + x2, data = dat_1))
summary(lm(y ~ x1 + x2 + x1*x2, data = dat_1))
cor(dat_2)
read.tables
?read.table
# hw_lect15_4
dat <- read.table("https://www.stat.washington.edu/marzban/390/winter20/hw_3_mult_simple_dat.txt", col.names = c("x1","x2","y"))
View(dat)
lm.7 <- lm(y ~ x1+x2, data = dat)
lm.7
summary(lm.7)
lm.8 <- lm(y ~ x1, data = dat)
lm.8 <- lm(y ~ x2, data = dat)
lm.8 <- lm(y ~ x1, data = dat)
lm.9 <- lm(y ~ x2, data = dat)
summary(lm.8)
summary(lm.9)
plot(x1,x2)
?plot
plot(dat)
plot(dat$x1,dat$x2)
plot(dat)
plot(dat$x1,dat$y)
plot(dat$x2,dat$y)
lm.7
lm.8
lm.9
cor(dat)
cor(dat$x1,dat$x2)
ntrial = 5000
x_max = numeric(ntrial)
x_min = numeric(ntrial)
par(mfrow=c(1,2))
for( trial in 1:ntrial ){
x = rnorm(50, 0, 1)
x_max[trial] = max(x)
x_min[trial] = min(x)
}
hist(x_min,x_max)
hist(x_min)
hist(x_max)
?rexp
xbar = numeric(ntrial)
for( trial in 1:ntrial ){
x = rexp(100,2)
xbar[trial] = mean(x)
}
qqnorm(xbar,cex = 0.5)
par(mfrow=c(1,1))
qqnorm(xbar,cex = 0.5)
abline(0.5,0.3)
abline(0.5,0.1)
abline(0.5,0.05)
qqnorm(xbar,cex = 0.5)
abline(0.5,0.05)
abline(0.51,0.05)
qqnorm(xbar,cex = 0.5)
abline(0.51,0.05)
qqnorm(xbar,cex = 0.5)
abline(0.5,0.05)
?abline
(1/2)/sqrt(5000)
(1/2)/sqrt(100)
# hw_lect14_1
dat_2 <- read.table("https://www.stat.washington.edu/marzban/390/winter20/transform_dat.txt",
header = T)
lm.2 <- lm(y ~ sqrt(x) + I(x))
plot(x,y)
View(dat_2)
plot(dat2$x,dat2$y)
plot(dat_2$x,dat_2$y)
plot(sqrt(dat_2$x),sqrt(dat_2$y))
lm.1 <- lm(sqrt(dat_2$y) ~ sqrt(dat_2$x))
abline(lm.1)
summary(lm.1)
lm.2
lm.2 <- lm(y ~ sqrt(x) + I(x),data = dat_2)
lm.2
plot(predict(lm.1), predict(lm.2))
dat <- read.csv(file.choose(), header = T)
View(dat)
y <- dat$Rebounds
x <- dat$Age
x <- dat$Positions
x <- dat$Pos
dat[dat$Pos == "C",]
dat[dat$Pos == "C", rebounds]
dat[dat$Pos == "C", Rebounds]
dat[dat$Pos == "C", dat$Rebounds]
dat[dat$Pos == "C",Rebounds]
dat[,Pos]
dat[,dat$Pos]
dat[dat$Pos == "C","Rebounds"]
mean(dat[dat$Pos == "C","Rebounds"])
mean(dat[dat$Pos == "PF","Rebounds"])
n(dat[dat$Pos == "C","Rebounds"])
dat[dat$Pos == "C","Rebounds"]
dat[dat$Pos == "PF","Rebounds"]
sd(dat[dat$Pos == "C","Rebounds"])
sd(dat[dat$Pos == "PF","Rebounds"])
x1 = c(-0.27, -0.14, 1.61, 0.09, 0.00, 2.07, 0.56, -1.67, -0.51, -0.54)
x2 = c(-0.32, 0.20, 1.93, 0.54, 0.75, 1.77, 0.84, -0.29, -0.33, 0.17)
mean(x1)
mean(x2)
sd(x1)
sd(x2)
plot(x1,x2)
cor(x1,x2)
x_diff <- x1-x2
mean(x1-x2)
mean(x_diff)
sd(x_diff)
mean(x1)-mean(x2)
sd(x1)^2+sd(x2^2)
sd(x_diff)^2
sd(x1)^2+sd(x2)^2
y1 = c(-0.27, -0.14, 1.61, 0.09, 0.00, 2.07, 0.56, -1.67, -0.51, -0.54)
y2 = c( 0.20 , 0.54, -0.33, 1.93, -0.32, 1.77, 0.75, 0.17, -0.29, 0.84)
plot(y1,y2)
cor(y1,y2)
mean(y1)
mean(y2)
sd(y1)
sd(y2)
numer <- ((1.4^2+1.1^2)/32)^2
deno <- 1/31*((1.4^2/32)+(1.1^2/32)^2)
numer/deno
deno <- 1/31*((1.4^2/32)^2+(1.1^2/32)^2)
numer/deno
sqrt(1.4^2/32+1.1^2/32)
sqrt(1.4^2/32+1.1^2/32)*2
sqrt(1.4^2/32+1.1^2/32)*1.671
dbinom(4, size=12, prob=0.2)
?dbinom
dbinom(1, size=500, prob=0.5/3.3)
dbinom(500, size=500, prob=0.5/3.3)
dbinom(450, size=500, prob=0.5/3.3)
dbinom(1:65, size=500, prob=0.5/3.3)
sum <- 0
for (i in 1:65) {
sum <- sum + dbinom(i, size=500, prob=0.5/3.3)
}
sum <- 0
for (i in 1:64) {
sum <- sum + dbinom(i, size=500, prob=0.5/3.3)
}
sum <- 0
for (i in 161:500) {
sum <- sum + dbinom(i, size=500, prob=1/3.3)
}
161:500
sum <- 0
for (i in 161:500) {
sum <- sum + dbinom(i, size=500, prob=1/3.3)
}
dbinom(65, size=500, prob=0.5/3.3)
sum <- 0
for (i in 0:64) {
sum <- sum + dbinom(i, size=500, prob=1/3.3)
}
sum <- 0
for (i in 0:64) {
sum <- sum + dbinom(i, size=500, prob=0.5/3.3)
}
sum <- 0
for (i in 161:500) {
sum <- sum + dbinom(i, size=500, prob=1/3.3)
}
dbinom(3, size=5, prob=1/2)
sum <- 0
for (i in 160:500) {
sum <- sum + dbinom(i, size=500, prob=1/3.3)
}
ntrial <- 160:500
for (i in ntrial) {
sum <- sum + dbinom(i, size=500, prob=1/3.3)
}
sum <- 0
ntrial <- 160:500
for (i in ntrial) {
sum <- sum + dbinom(i, size=500, prob=1/3.3)
}
toothpaste <- c(0.52, 0.65, 0.46, 0.50, 0.37)
mean(toothpaste)
sd(toothpaste)
std(toothpaste)
MSI <- c(0.39,0.84,1.76,3.35,4.69,7.70,10.52,10.92)
SIB <- c(0.36,1.35,2.56,3.92,5.35,8.33,10.70,10.91)
diff <- MSI - SIB
mean(diff)
sd(diff)
xbar <- mean(diff)
s <- sd(diff)
t <- xbar/(s/sqrt(8))
obs.counts = matrix(c(728,1304,495,1072,2800,1193), ncol = 3, byrow = T)
obs.counts
728/1800
1304/4104
495/1600
total = sum(obs.counts)
?apply
?t
rowsum <- apply(obs.count, 1, sum)
rowsum <- apply(obs.counts, 1, sum)
matrix(rowsum)
rowsum
type(rowsum)
typeof(rowsum)
colsum <- apply(obs.counts, 2, sum)
?%*%
%*%
matrix(rowsum)
t(matrix(colsum))
matrix(rowsum) %*% t(matrix(colsum))
2527*1900
2527*1800
matrix(rowsum) * t(matrix(colsum))
dat <- read.csv(file.choose(), header = T)
points <- dat$Points
View(dat)
pos <- dat$Pos
dat <- read.csv(file.choose(), header = T, stringsAsFactors = F)
points <- dat$Points
pos <- dat$Pos
x<- dat$Pos
y <- dat$Points
dat <- read.table("https://www.stat.washington.edu/marzban/390/winter20/9_1_dat", header = T)
View(dat)
aov.1 <- aov(Vibration ~ as.factor(Brand), data = dat)
summary(aov.1)
boxplot(Vibration ~ Brand, data = dat)
my_dat <- read.csv(file.choose(), header = T, stringsAsFactors = F)
x<- my_dat$Pos
anova <- aov(Points ~ Pos, data = my_dat)
summary(anova)
# hw_lect26_1
n = 10
n.trial - 5000
x = c(1:n)
y_true = 10 + 2*x
sigma_eps = 15
set.seed(123)
y_obs = y_true + rnorm(n,0,sigma_eps)
lm.1 = lm(y_obs ~ x)
summary(lm.1)
names(lm.1)
lm.1$coefficients
alpha = numeric(n.trial)
n.trial = 5000
alpha = numeric(n.trial)
beta = numeric(n.trial)
lm.1$coefficients[1]
n = 10
n.trial = 5000
x = c(1:n)
y_true = 10 + 2*x
sigma_eps = 15
beta = numeric(n.trial)
set.seed(123)
for (trial in 1:n.trial) {
y_obs = y_true + rnorm(n,0,sigma_eps)
lm.1 = lm(y_obs ~ x)
beta[trial] = lm.1$coefficients[2]
}
mean(beta)
(n-1)*(sd(x)^2)
Sxx <- (n-1)*(sd(x)^2)
sd(beta)
sigma_eps/Sxx
sigma_eps/sqrt(Sxx)
sd(beta)
sigma_eps/sqrt(Sxx)
qqnorm(beta, cex = 0.5)
abline(mean(beta),sd(beta))
abline(mean(beta),sd(beta), col=2)
# hw_lect27_1
x <- c(89, 177, 189, 354, 362, 442, 965)
y <- c(.40)
y <- c(.40, .60, .48, .66, .61, .69, .99)
# part a
plot(x,y)
# part b
lm.27 <- lm(y ~ x)
lm.27$coefficients[2]
# part c
summary(lm.27)
names(lm.27)
y = 1 + rnorm(n,0,1)
set.seed(123) # Use this line to make sure we all get the same answes.
n = 20
y = 1 + rnorm(n,0,1)
?runif
x1 = runif(n,-1,1)
x2 = runif(n,-1,1)
x3 = runif(n,-1,1)
x4 = runif(n,-1,1)
x5 = runif(n,-1,1)
x6 = runif(n,-1,1)
x7 = runif(n,-1,1)
x8 = runif(n,-1,1)
x9 = runif(n,-1,1)
x10 = runif(n,-1,1)
lm.28 <- lm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10)
summary(lm.28)
lm.27$coefficients[2]
summary(lm.27)
lm.27$coefficients[2]*250+lm.27$coefficients[1]
lm.27$coefficients[2]*250
anova(lm.27)
lm.27$coefficients[1]
# part d
# part e
lm.27$coefficients[2]*250+lm.27$coefficients[1]
names(lm.27)
lm.27$residuals
lm.27$effects
s_e <- 0.05405
sqrt(1/7+((250-mean(x))^2)/(6*(sd(x)^2)))*s_e
# part f
sqrt(1+1/7+((250-mean(x))^2)/(6*(sd(x)^2)))*s_e
dat <- read.table("https://www.statcrunch.com/app/index.php?dataid=1843341")
dat <- read.table("https://www.statcrunch.com/app/index.php?dataid=1843341", header = T)
View(iris)
hist(iris$Sepal.Length)
View(iris)
knitr::opts_chunk$set(echo = TRUE)
install.packages("tseries")
library(tseries)
asset.names = "spy"
start.date = "2020-1-1"
end.date = "2020-6-1"
spy.prices = get.hist.quote(instrument="spy", start=start.date,
end=end.date, quote="Open",
provider="yahoo", origin="1970-01-01",
compression="d", retclass="zoo")
spy.prices
spy.prices = get.hist.quote(instrument="spy", start=start.date,
end=end.date, quote="Open",
provider="yahoo", origin="1970-01-01",
compression="m", retclass="zoo")
spy.prices
end.date = "2020-6-2"
spy.prices = get.hist.quote(instrument="spy", start=start.date,
end=end.date, quote="Open",
provider="yahoo", origin="1970-01-01",
compression="m", retclass="zoo")
spy.prices
dim(spy.prices)
spy.prices[0,:]
spy.prices[0,]
spy.prices[,0]
spy.prices[,1]
Sys.which("make")
write('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', file = "~/.Renviron", append = TRUE)
library("MatchIt")
# nearest neighbor
m.out <- matchit(matching$unemployment_treated ~ matching$Some.college.raw.value + matching$Median.household.income.raw.value,
data = matching, method = methods[1], distance = distances[1], caliper = 0.39)
summary(m.out)
plot(m.out, type = "jitter", interactive = FALSE)
library("MatchIt")
# nearest neighbor
m.out <- matchit(matching$unemployment_treated ~ matching$Some.college.raw.value + matching$Median.household.income.raw.value,
data = matching, method = methods[1], distance = distances[1], caliper = 0.39)
library("MatchIt")
# nearest neighbor
m.out <- matchit(matching$unemployment_treated ~ matching$Some.college.raw.value + matching$Median.household.income.raw.value,
data = matching, method = methods[1], distance = distances[1], caliper = 0.39)
methods = c("nearest", "optimal", "full", "genetic")
distances = c("glm", "mahalanobis")
# nearest neighbor
m.out <- matchit(matching$unemployment_treated ~ matching$Some.college.raw.value + matching$Median.household.income.raw.value,
data = matching, method = methods[1], distance = distances[1], caliper = 0.39)
# # 1:1 NN PS matching w/o replacement
matching <- read.csv(file = '../../../data/processed_data/df_matching.csv')
setwd("D:/UW/courses/Autumn 2021/CSE 481DS/cse481ds-mental-health/notebooks/county_level/Matching Analysis")
# # 1:1 NN PS matching w/o replacement
matching <- read.csv(file = '../../../data/processed_data/df_matching.csv')
# nearest neighbor
m.out <- matchit(matching$unemployment_treated ~ matching$Some.college.raw.value + matching$Median.household.income.raw.value,
data = matching, method = methods[1], distance = distances[1], caliper = 0.39)
summary(m.out)
plot(m.out, type = "jitter", interactive = FALSE)
# nearest neighbor
m.out <- matchit(matching$unemployment_treated ~ matching$Some.college.raw.value + matching$Median.household.income.raw.value,
data = matching, method = methods[1], distance = distances[1], replace = TRUE)
summary(m.out)
plot(m.out, type = "jitter", interactive = FALSE)
# get rid of treated with propensity score greater than control
m.data1 <- match.data(m.out)
untreated <- (m.data1[["unemployment_treated"]] == 0)
untreated.data <- m.data1[untreated,]
distance_greatest <- (untreated.data[["distance"]] == max(untreated.data[["distance"]]))
untreated_greatest_dist <- untreated.data[distance_greatest, "distance"]
# create a new column: assign "too high" if distance greater than untreated_greatest_dist, "normal"
m.data1$too_high <- (m.data1$distance >untreated_greatest_dist)
ggplot(data = m.data1) +
geom_point(mapping = aes(x = Some.college.raw.value, y = Median.household.income.raw.value, color = too_high)) +
geom_hline(yintercept=72092.05, linetype="dashed", color = "red") +
geom_vline(xintercept=0.7489542, linetype="dashed", color = "red")
# for plotting
library("ggplot2")
ggplot(data = m.data1) +
geom_point(mapping = aes(x = Some.college.raw.value, y = Median.household.income.raw.value, color = too_high)) +
geom_hline(yintercept=72092.05, linetype="dashed", color = "red") +
geom_vline(xintercept=0.7489542, linetype="dashed", color = "red")
ggplot(data = m.data1) +
geom_point(mapping = aes(x = Some.college.raw.value, y = Median.household.income.raw.value, color = unemployment_treated)) +
geom_hline(yintercept=72092.05, linetype="dashed", color = "red") +
geom_vline(xintercept=0.7489542, linetype="dashed", color = "red")
# Do matching on unemployment again
m.out <- matchit(matching_sub$unemployment_treated ~ matching_sub$Some.college.raw.value + matching_sub$Median.household.income.raw.value,
data = matching_sub, method = methods[1], distance = distances[1], replace = TRUE, reuse.max = 2)
matching_sub = matching[normal_college & normal_income, ]
# Use less than 95% of college (0.7489542) and median household income (72092.05)
college_values <- quantile(m.data1$Some.college.raw.value, c(.25, .50,  .75, .90, .95))
income_values <- quantile(m.data1$Median.household.income.raw.value, c(.25, .50,  .75, .90, .95))
normal_college <- (matching$Some.college.raw.value <= college_values[5])
normal_income <- (matching$Median.household.income.raw.value <= income_values[5])
matching_sub = matching[normal_college & normal_income, ]
# Do matching on unemployment again
m.out <- matchit(matching_sub$unemployment_treated ~ matching_sub$Some.college.raw.value + matching_sub$Median.household.income.raw.value,
data = matching_sub, method = methods[1], distance = distances[1], replace = TRUE, reuse.max = 2)
summary(m.out)
plot(m.out, type = "jitter", interactive = FALSE)
# nearest neighbor
m.out <- matchit(matching$unemployment_treated ~ matching$Some.college.raw.value + matching$Median.household.income.raw.value + matching$RUCC +
matching$Ratio.of.population.to.mental.health.providers,
data = matching, method = methods[1], distance = distances[1], replace = TRUE)
summary(m.out)
plot(m.out, type = "jitter", interactive = FALSE)
# get rid of treated with propensity score greater than control
m.data1 <- match.data(m.out)
untreated <- (m.data1[["unemployment_treated"]] == 0)
untreated.data <- m.data1[untreated,]
distance_greatest <- (untreated.data[["distance"]] == max(untreated.data[["distance"]]))
untreated_greatest_dist <- untreated.data[distance_greatest, "distance"]
# create a new column: assign "too high" if distance greater than untreated_greatest_dist, "normal"
m.data1$too_high <- (m.data1$distance >untreated_greatest_dist)
# plotting
ggplot(data = m.data1) +
geom_point(mapping = aes(x = Some.college.raw.value, y = Median.household.income.raw.value, color = unemployment_treated)) +
geom_hline(yintercept=72092.05, linetype="dashed", color = "red") +
geom_vline(xintercept=0.7489542, linetype="dashed", color = "red")
# plotting
ggplot(data = m.data1) +
geom_point(mapping = aes(x = Some.college.raw.value, y = Median.household.income.raw.value, color = too_high)) +
geom_hline(yintercept=72092.05, linetype="dashed", color = "red") +
geom_vline(xintercept=0.7489542, linetype="dashed", color = "red")
cor(matching)
View(matching)
cor(matching[,4:13])
cor_matrix = cor(matching[,4:13])
View(cor_matrix)
cor_matrix = cor(matching[,5:13])
cor_matrix = cor(matching[complete.cases(final[ , 12]),5:13])
cor_matrix = cor(matching[complete.cases(matching[ , 12]),5:13])
# nearest neighbor
m.out <- matchit(matching$unemployment_treated ~ matching$Some.college.raw.value + matching$Median.household.income.raw.value,
data = matching, method = methods[1], distance = distances[1], replace = TRUE)
summary(m.out)
plot(m.out, type = "jitter", interactive = FALSE)
# get rid of treated with propensity score greater than control
m.data1 <- match.data(m.out)
untreated <- (m.data1[["unemployment_treated"]] == 0)
untreated.data <- m.data1[untreated,]
distance_greatest <- (untreated.data[["distance"]] == max(untreated.data[["distance"]]))
untreated_greatest_dist <- untreated.data[distance_greatest, "distance"]
# create a new column: assign "too high" if distance greater than untreated_greatest_dist, "normal"
m.data1$too_high <- (m.data1$distance >untreated_greatest_dist)
# plotting
ggplot(data = m.data1) +
geom_point(mapping = aes(x = Some.college.raw.value, y = Median.household.income.raw.value, color = too_high)) +
geom_hline(yintercept=72092.05, linetype="dashed", color = "red") +
geom_vline(xintercept=0.7489542, linetype="dashed", color = "red")
ggplot(data = m.data1) +
geom_point(mapping = aes(x = Some.college.raw.value, y = Median.household.income.raw.value, color = unemployment_treated)) +
geom_hline(yintercept=72092.05, linetype="dashed", color = "red") +
geom_vline(xintercept=0.7489542, linetype="dashed", color = "red")
# Use less than 95% of college (0.7489542) and median household income (72092.05)
college_values <- quantile(m.data1$Some.college.raw.value, c(.25, .50,  .75, .90, .95))
income_values <- quantile(m.data1$Median.household.income.raw.value, c(.25, .50,  .75, .90, .95))
normal_college <- (matching$Some.college.raw.value <= college_values[5])
normal_income <- (matching$Median.household.income.raw.value <= income_values[5])
matching_sub = matching[normal_college & normal_income, ]
# Do matching on unemployment again
m.out <- matchit(matching_sub$unemployment_treated ~ matching_sub$Some.college.raw.value + matching_sub$Median.household.income.raw.value,
data = matching_sub, method = methods[1], distance = distances[1], replace = TRUE, reuse.max = 2)
summary(m.out)
plot(m.out, type = "jitter", interactive = FALSE)
# TODO: estimating effect of unemployment. A bit trickier because replacement is used
# See https://kosukeimai.github.io/MatchIt/articles/estimating-effects.html
# Not sure how to do it with replacement
gm <- get_matches(m.out)
View(gm)
fitmd <- lm(Poor.mental.health.days.raw.value ~ unemployment_treated + Some.college.raw.value +
Median.household.income.raw.value, data = gm,
weights = weights)
coeftest(fit1gm, vcov. = vcovCL, cluster = ~subclass + id)["A",,drop = FALSE]
install.packages("lmtest")
